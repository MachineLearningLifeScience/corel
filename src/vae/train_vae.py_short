from warnings import warnfrom experiments.assets.data.rfp_fam import train_datasetfrom experiments.assets.data.rfp_fam import test_datasetfrom models import VAE# TODO: make this alphabet part of a ProblemInfoAMINO_ACIDS = [            "A",            "R",            "N",            "D",            "C",            "E",            "Q",            "G",            "H",            "I",            "L",            "K",            "M",            "F",            "P",            "S",            "T",            "W",            "Y",            "V",            "-",        ]def encode_dataset(ds: tf.data.Dataset, alphabet=AMINO_ACIDS):    lookup = tf.keras.layers.StringLookup(vocabulary=alphabet, output_mode="one_hot")    encoded_ds = ds.map(lambda x: lookup(x))    return encoded_dsif __name__ == "__main__":    BATCHSIZE = 256    EPOCHS = 15    SEED = 42    LR = 1e-3    if tf.test.gpu_device_name() != "/device:GPU:0":        warn("GPU device not found.")    else:        print(f"SUCCESS: Found GPU: {tf.test.gpu_device_name()}")    # TODO: create TF dataset class from RFP MSA    #datasets = tfds.load(name="rfp_fam", as_supervised=False)  FIXME: rfp_fam does not registered    train_dataset = train_dataset.batch(BATCHSIZE).prefetch(tf.data.AUTOTUNE).shuffle(SEED)    train_dataset = train_dataset.apply(encode_dataset)    eval_dataset = test_dataset.batch(BATCHSIZE).prefetch(tf.data.AUTOTUNE)    eval_dataset = eval_dataset.apply(encode_dataset)    x0 = train_dataset.take(1).get_single_element()    vae = VAE(z_dim=10, input_dims=x0.shape, n_categories=tf.constant(len(AMINO_ACIDS)))    optimizer = tf.optimizers.Adam(learning_rate=LR)    vae.model.compile(optimizer=optimizer, loss=vae.neg_ll)    _ = vae.fit(train_dataset, epochs=EPOCHS, vaidation_data=eval_dataset)